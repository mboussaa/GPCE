%\section{Background and Motivation}

%\vspace*{-0.3cm}


\section{Motivation}

\subsection{Code Generator Families}

In different domain, the use of code generator is a common practice. We can cite three approaches that intensively develop and use code generators. 

\paragraph{a. Haxe.} 	Haxe\footnote{\url{http://haxe.org/}}~\cite{dasnois2011haxe} is an open source toolkit for cross-platform development which compiles to a number of different programming platforms, including JavaScript, Flash, PHP, C++, C\#, and Java. Haxe involves many features: the Haxe language, multi-platform compilers, and different native libraries. The Haxe language is a high-level programming language which is strictly typed. This language supports both, functional and object-oriented programming paradigms. It has a common type hierarchy, making certain API available on every targeted platform. Moreover, Haxe comes with a set of code generators that translate manually-written code (in Haxe language) to different target languages and platforms.  Haxe code can be compiled for applications running on desktop, mobile and web platforms. Compilers ensure the correctness of user code in terms of syntax and type safety. Haxe comes also with a set of standard libraries that can be used on all supported targets and platform-specific libraries for each of them. One of the main usage of Haxe is to develop Cross-Platform Games or Cross-Platform libraries that can run on mobile, on the Web or on a Desktop.  This project is popular (more than \num{1440} stars on GitHub).

\paragraph{b. ThingML.} ThingML\footnote{\url{http://thingml.org/}} is a modeling language for embedded and distributed systems~\cite{fleurey2011mde}. The idea of ThingML is to develop a practical model-driven software engineering tool-chain which targets resource constrained embedded systems such as low-power sensor and microcontroller based devices. ThingML is developed as a domain-specific modeling language which includes concepts to describe both software components and communication protocols. The formalism used is a combination of architecture models, state machines and an imperative action language. The ThingML toolset provides a  code generators family  to translate ThingML to C, Java and JavaScript. It includes a set of variants for the C and JavaScript code generators to target different embedded system and their constraints. 
This project is still confidential but it is a good candidate to represent the modeling community practices.
 
\paragraph{c. TypeScript.} TypeScript\footnote{\url{https://www.typescriptlang.org/}}is a typed superset of JavaScript that compiles to plain JavaScript~\cite{rastogi2015safe}. In fact, it does not compile to only one version of JavaScript. It can transform TypeScript to EcmaScript 3, 5 or 6. It can generate JavaScript that uses different system modules ('none', 'commonjs', 'amd', 'system', 'umd', 'es6', or 'es2015')\footnote{Each of this variation point can target different code generators (function \textit{emitES6Module} vs \textit{emitUMDModule} in emitter.ts for example).}. 
This project is popular (more than \num{12619} stars on GitHub).


\subsection{Functional Correctness of a Code Generator Family}


A reliable and acceptable way to increase the confidence in the correctness of code generators is to validate and check the functionality of generated code, which is a common practice for compiler validation and testing.
Therefore, developers try to check the syntactic and semantic correctness of the generated code by means of different techniques such as static analysis, test suites, etc., and ensure that the code is behaving correctly.  In model-based testing for example~\cite{jorges2014back,stuermer2007systematic}, testing code generators focuses on testing the generated code against its design. Thus, the model and the generated code are executed in parallel, by means of simulations, with the same set of test suites. Afterwards, the two outputs are compared with respect to certain acceptance criteria. Test cases, in this case, can be designed to maximize the code or model coverage~\cite{sturmer2005overview}. 
Based on the three sample projects presented above, we observe on their GitHub code repository that they all use unit tests to check the correctness of the code generators.  

\subsection{Performance Evaluation of a Code Generator Family}


Code generators have to respect different requirements to preserve software reliability and quality~\cite{demertzi2011analyzing}. A non-efficient code generator might generate defective software artifacts (code smells) that violates common software engineering practices. Thus, poor-quality code can affect system reliability and performance (e.g., high resource usage, low execution speed, etc.). Thus, another important aspect of code generator's testing is to test the non-functional properties of produced code. Proving that the generated code is functionally correct is not enough to claim the effectiveness of the code generator under test. In looking at the three motivating examples, we can observe that ThingML and TypeScript do not provide any specific test to check the consistency of the different memory usage or CPU consumption regarding the different code generators and their variants. Haxe provides two test cases \footnote{https://github.com/HaxeFoundation/haxe/tree/development/tests/benchs} to benchmark the resulting generated code. One serves to benchmark an example in which object allocations are deliberately (over) used to measure how memory access/GC mixes with numeric processing in different target languages. The second test mainly bench the network speed for each target platform. 

However, based on existing benchmarks between technical environments~\cite{hundt2011loop}, in comparing the behavior of the generated code of a large data set of programs, our feeling is that we could detect inefficient code generators. The kinds of error we track are the following:
\begin{itemize}
	\setlength\itemsep{0em}
	\item  the lack of use of a \textbf{specific function that exists in the standard library} of the targeted language  that can speed or reduce the memory consumption of the resulting program.
	\item the lack of use of \textbf{a specific type that exists in the standard library} of the targeted language  that can speed or reduce the memory consumption of the resulting program.
	\item  the lack of use of\textbf{ a specific language feature in a targeted language}  that can speed or reduce the memory consumption of the resulting program. 
\end{itemize}

The main difficulties is the fact that, for testing the non functional properties of a code generator such as performance, we cannot just observe the execution of the code generator but we have to observe and compare the execution of the generated program. Even if there is no exact oracle to detect inconsistencies, we could benefit from the family of code generators to compare the behavior of several programs generated from the same source that runs atop different technical stacks. 

Next section discusses the common process used by a developer to automatically test the performance of a generated code and illustrates how we can benefit from the code generators families to identify singular behavior that could reveal bugs in a code generator. 


%In short, then, we believe that testing the non-functional properties of code generators remains challenging and time-consuming task because developers have to analyze and verify code for each target platform using platform-dependent tools which makes the task of maintaining code generators very tedious. The heterogeneity of platforms and the diversity of target software languages increase the need of supporting tools that can evaluate the consistency and coherence of generated code regarding the non-functional properties. This paper describes a new approach, based on micro-services as execution platforms, to automate and ease the non-functional testing of code generators. This runtime monitoring infrastructure provides a fine-grained understanding of resource consumption and analysis of generated code's behavior.



 



