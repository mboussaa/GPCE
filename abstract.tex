\begin{abstract}
The intensive use of generative programming techniques provides an elegant engineering solution to deal with the heterogeneity of platforms or technological stacks. The use of Domain Specifics Language, for example, leads to the creation of numerous code generators that automatically translate high-level system specifications into multi-target executable code. 
Producing correct and efficient code generator is complex and error-prone. Although software designers provide generally high-level test suites to verify the functional outcome of generated code, it remains challenging and tedious to verify the behavior of produced code in terms of non-functional properties.
This paper describes a practical approach based on a runtime monitoring infrastructure to automatically check potential inefficient code generators. This infrastructure, based on system containers as execution platforms, allows code-generator developers to evaluate the generated code performance.
We evaluate our approach by analyzing the non-functional properties of Haxe, a popular high-level programming language that involves a set of cross-platform code generators that target different platforms. 
Experimental results show that our approach is able to detect some performance inconsistencies among Haxe generated code that reveal issues in code generators.
\end{abstract}
 

\category{D.3.4}{Programming Languages}{Processorsâ€“ compilers, code generation}

% general terms are not compulsory anymore,
% you may leave them out
\terms
Generative Programming, Testing, Components

\keywords
code quality, non-functional properties, code generator, testing